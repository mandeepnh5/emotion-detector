{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kLuIO4EKBKbU"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yPcCYf5XBKbV","outputId":"7ee5300f-5745-4c57-bb31-9f253b920e68"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/da23c022/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","/home/da23c022/miniconda3/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.15 (you have 1.4.14). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n","  check_for_updates()\n","/home/da23c022/miniconda3/lib/python3.10/site-packages/pydantic/main.py:211: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n","  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20 - Loss: 1.5629, Accuracy: 0.3902\n","Epoch 2/20 - Loss: 1.3452, Accuracy: 0.4984\n","Epoch 3/20 - Loss: 1.2593, Accuracy: 0.5387\n","Epoch 4/20 - Loss: 1.1248, Accuracy: 0.5904\n","Epoch 5/20 - Loss: 1.0440, Accuracy: 0.6224\n","Epoch 6/20 - Loss: 0.9297, Accuracy: 0.6709\n","Epoch 7/20 - Loss: 0.8294, Accuracy: 0.6973\n","Epoch 8/20 - Loss: 0.5908, Accuracy: 0.7947\n","Epoch 9/20 - Loss: 0.5338, Accuracy: 0.8224\n","Epoch 10/20 - Loss: 0.4754, Accuracy: 0.8269\n","Epoch 11/20 - Loss: 0.4708, Accuracy: 0.8000\n","Epoch 12/20 - Loss: 0.4163, Accuracy: 0.8327\n","Epoch 13/20 - Loss: 0.4602, Accuracy: 0.8184\n","Epoch 14/20 - Loss: 0.4803, Accuracy: 0.8256\n","Epoch 15/20 - Loss: 0.4081, Accuracy: 0.8564\n","Epoch 16/20 - Loss: 0.3694, Accuracy: 0.8769\n","Epoch 17/20 - Loss: 0.3784, Accuracy: 0.8498\n","Epoch 18/20 - Loss: 0.3758, Accuracy: 0.8398\n","Epoch 19/20 - Loss: 0.3472, Accuracy: 0.8762\n","Epoch 20/20 - Loss: 0.3532, Accuracy: 0.8596\n","Validation Accuracy: 0.6580\n"]}],"source":["import cv2\n","import numpy as np\n","import pandas as pd\n","from PIL import Imageimport torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","import timm  # For Swin Transformer and other models\n","\n","import csv\n","\n","# Custom Dataset Class\n","class EmotionDataset(Dataset):\n","    def __init__(self, df, transform=None):\n","        self.df = df\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, ids):\n","        img = np.array(self.df['pixels'].iloc[ids].split(), dtype='float32').reshape(48, 48)\n","        img = Image.fromarray(img).convert('L')  # Converts to grayscale\n","        img = img.convert(\"RGB\")  # Convert a  grayscale image to 3-channel RGB image\n","\n","        if self.transform:\n","            img = np.array(img)\n","            img = self.transform(image=img)['image']\n","        label = self.df['emotion'].iloc[ids]\n","        return img, label\n","\n","\n","# Mixup Function\n","def mixup_data(x, y, alpha=1.0):\n","\n","    if alpha > 0:\n","        lambd = np.random.beta(alpha, alpha)\n","    else:\n","        lambd = 1\n","\n","    batch_size = x.size()[0]\n","    index = torch.randperm(batch_size).to(x.device)\n","\n","    mixed_x = lambd * x + (1 - lambd) * x[index, :]\n","    y_a, y_b = y, y[index]\n","    return mixed_x, y_a, y_b, lambd\n","\n","# Mixup loss function\n","def mixup_criterion(criterion, pred, y_a, y_b, lambd):\n","    return lambd * criterion(pred, y_a) + (1 - lambd) * criterion(pred, y_b)\n","\n","\n","#  Data Augmentations for Centered and Aligned Faces\n","train_transform = A.Compose([\n","    A.Resize(224, 224, interpolation=cv2.INTER_CUBIC),  # Resize to 224x224\n","    A.HorizontalFlip(p=0.5),  # Flip the image horizontally\n","    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=35, p=0.7),  # Small shifts, scaling, and rotations\n","    A.GaussNoise(var_limit=(10.0, 30.0), p=0.7),  # Add Gaussian noise\n","    A.GaussianBlur(blur_limit=3, p=0.2),  # Simulate blur\n","    A.RandomGamma(gamma_limit=(80, 120), p=0.7),  # Adjust brightness and contrast\n","    A.RandomBrightnessContrast(p=0.7),  # Random brightness and contrast\n","    A.Normalize(mean=(0.5,), std=(0.5,)),  # Normalize for grayscale images\n","    ToTensorV2(),  # Convert to tensor\n","])\n","\n","val_transform = A.Compose([\n","    A.Resize(224, 224, interpolation=cv2.INTER_CUBIC),  # Resize to 224x224 using bilinear interpolation\n","    A.Normalize(mean=(0.5,), std=(0.5,)),\n","    ToTensorV2(),\n","])\n","\n","\n","# Function to get call for optimizer optimizer\n","def get_optimizer(optimizer_name, model, lr):\n","    if optimizer_name == 'adam':\n","        return optim.Adam(model.parameters(), lr=lr)\n","\n","\n","# Training loop with Mixup\n","def train_model_with_mixup(model, optimizer, scheduler, num_epochs=10, mixup_prob=0.5):\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        running_corrects = 0\n","        total_samples = 0\n","\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","\n","            # Apply Mixup with a given probability\n","            if np.random.rand() < mixup_prob:\n","                inputs, targets_a, targets_b, lambd = mixup_data(inputs, labels, alpha=1.0)\n","                outputs = model(inputs)\n","                loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lambd)\n","            else:\n","                # No Mixup, normal forward pass\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Accumulate loss and correct predictions\n","            running_loss += loss.item() * inputs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            running_corrects += torch.sum(preds == labels).item()\n","            total_samples += labels.size(0)\n","\n","        # Scheduler step\n","        scheduler.step()\n","\n","        # Calculate average loss and accuracy for the epoch\n","        epoch_loss = running_loss / total_samples\n","        epoch_acc = running_corrects / total_samples\n","\n","        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n","\n","    return model\n","\n","# Load and preprocess data\n","train_df = pd.read_csv('data_cv/train_dataset_cv.csv')\n","train_df, val_df = train_test_split(train_df, test_size=0.05, stratify=train_df['emotion'], random_state=42)\n","\n","# Create Datasets\n","train_dataset = EmotionDataset(df=train_df, transform=train_transform)\n","val_dataset = EmotionDataset(df=val_df, transform=val_transform)\n","\n","# Dataloader\n","train_loader = DataLoader(train_dataset, batch_size=95, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=95, shuffle=False)\n","\n","# Device setup\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Class Weights for handling class imbalance\n","class_weights = torch.FloatTensor([1.0, 2.0, 1.0, 0.5, 1.5, 0.7, 1.0]).to(device)\n","criterion = nn.CrossEntropyLoss(weight=class_weights)\n","\n","# Model setup (Swin Transformer)\n","swin_Model = timm.create_model('swin_base_patch4_window7_224', pretrained=True, num_classes=7)\n","swin_Model = swin_Model.to(device)\n","\n","# Optimizer and Scheduler\n","optimizer_swin = get_optimizer('adamw', swin_Model, lr=1e-4)\n","scheduler_swin = lr_scheduler.StepLR(optimizer_swin, step_size=7, gamma=0.1)\n","\n","# Train the model\n","swin_Model = train_model_with_mixup(swin_Model, optimizer_swin, scheduler_swin, num_epochs=20, mixup_prob=0.2)\n","\n","# Evaluate model on validation set\n","correct = 0\n","total = len(val_dataset)\n","with torch.no_grad():\n","    swin_Model.eval()\n","    for inputs, labels in val_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        outputs = swin_Model(inputs)\n","        _, preds = torch.max(outputs, 1)\n","        correct += torch.sum(preds == labels).item()\n","\n","accuracy = correct / total\n","print(f\"Validation Accuracy: {accuracy:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mrHitCvvBKba"},"outputs":[],"source":["\n","\n","# Custom Test Dataset Class without labels\n","class TestEmotionDataset(Dataset):\n","    def __init__(self, df, transform=None):\n","        self.df = df\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, ids):\n","        img = np.array(self.df['pixels'].iloc[ids].split(), dtype='float32').reshape(48, 48)\n","        img = Image.fromarray(img).convert('L')  # Convert to grayscale\n","        img = img.convert(\"RGB\")  # Convert grayscale to 3-channel RGB\n","\n","        if self.transform:\n","            img = np.array(img)\n","            img = self.transform(image=img)['image']\n","        img_id = self.df['id'].iloc[ids]\n","        return img, img_id\n","\n","# Test data Loading\n","test_df = pd.read_csv('data_cv/test_dataset_cv.csv')\n","\n","# Create test dataset and dataloader\n","test_dataset = TestEmotionDataset(df=test_df, transform=val_transform)\n","test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n","\n","# Inference on test data\n","def predict_test(model, test_loader):\n","    model.eval()\n","    predictions = []\n","    ids = []\n","    with torch.no_grad():\n","        for inputs, img_ids in test_loader:\n","            inputs = inputs.to(device)\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","            predictions.extend(preds.cpu().numpy())\n","            ids.extend(img_ids)\n","    return ids, predictions\n","\n","# Get test predictions\n","ids, predictions = predict_test(swin_Model, test_loader)\n","\n","\n","\n"]},{"cell_type":"code","source":["import pandas as pd\n","# Create a DataFrame from the lists\n","df = pd.DataFrame({'id': ids, 'emotion': predictions})\n","\n","# Save the DataFrame to a CSV file\n","df.to_csv('predictions.csv', index=False)"],"metadata":{"id":"0xtE5WsXCqBl"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}